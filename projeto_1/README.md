# Treinamento de redes neurais com transfer learning

üìå Neste projeto uso a t√©cnica de Transfer Learning para classifica√ß√£o multilabel de atributos faciais com a rede ResNet50.

A solu√ß√£o est√° neste diret√≥rio, no notebook do Google Colab [`Treinamento_de_redes_neurais_com_transfer_learning.ipynb`](https://github.com/FlaviaLopes/dio-challenges-coding-the-future-with-baires-dev/blob/main/projeto_1/Treinamento_de_redes_neurais_com_transfer_learning.ipynb).

$Mas$ $antes$ $disso$... Entenda um pouco mais sobre o desafio.

> **Desafio:** 
"O projeto consiste em aplicar o m√©todo de Transfer Learning em uma rede de Deep Learning usando a linguagem Python e no ambiente COLAB. Neste projeto, voc√™ pode usar sua pr√≥pria base de dados (exemplo: fotos suas, dos seus pais, dos seus amigos, dos seus animais dom√©sticos, etc). O exemplo de gatos e cachorros pode ser substitu√≠do por duas outras classes do seu interesse. O Dataset criado em nosso projeto anterior pode ser utilizado agora."

üéØ **Etapas**
- Para atingir os objetivos propostos, as seguintes etapas foram realizadas:  
  1. **Escolha da base e prepara√ß√£o dos dados:** escolhi o dataset CelebA (ver se√ß√£o 1).  
  2. **Implementa√ß√£o de Transfer Learning com a rede ResNet50:** retreinei a rede com as imagens do dataset selecionado (ver se√ß√£o 2).  
  3. **Treinamento e valida√ß√£o do modelo com m√©tricas espec√≠ficas:** utilizei as m√©tricas AUC, recall e precision (ver se√ß√£o 3).

üìù **Contexto**: A se√ß√£o 1 d√° mais detalhes sobre a base utilizada, as se√ß√µes 2 a 4 trazem mais informa√ß√µes sobre a rede utilizada, m√©tricas de avalia√ß√£o e o processo de transfer learning.

---
üîç **Desempenho do modelo**
- Training phase:
	- A cabe√ßa da rede ResNet50 foi treinada por 10 √©pocas com um total de 3.800 imagens. 
	> _obs_: foram escolhidas aleatoriamente para cada classe 100 imagens
- Fine tunning phase:
	- As primeiras 10 camadas continuaram congeladas, e as demais foram descongeladas para que o treinamento continuasse, a uma taxa de aprendizado menor, por mais 20 √©pocas.
- A imagem a seguir resume a evolu√ß√£o do treinamento atrav√©s das m√©tricas: AUC, Precision, Recall e loss (binary cross entropy). O tra√ßo vertical indica o in√≠cio do fine tunning, onde o desempenho cai, naturalmente, mas depois come√ßa a evoluir e convergir.

![Training metrics](../assets/images/ResNet50_CelebA_training_finetune_history.png)

- A seguir, temos dois exemplos de celebridades brasileiras e como foram classificadas pela rede.

![Eu](https://github.com/FlaviaLopes/dio-challenges-coding-the-future-with-baires-dev/blob/main/assets/images/eu.jpg)
![Eu](../assets/images/selton-mello.jpg)
---
üîç **Como o modelo classificou a minha foto**
![Eu](..assets/images/eu.jpg)

---
## üì∏ 1. CelebA dataset
---
O **CelebA** √© um dataset de imagens de rostos de celebridades, desenvolvido por pesquisadores da **The Chinese University of Hong Kong**. Cont√©m mais de 202 mil imagens rotuladas com 40 atributos faciais bin√°rios, como _smiling_, _young_, _black-hair_, _brown-hair_, _blond-hair_, _big-lips_, dentre outros. √â uma base bastante √∫til para treinamento de modelos de reconhecimento de atributos faciais.
Embora o enunciado mencione uma dataset com duas classes, optei por utilizar todas as 40 classes do dataset para explorar a complexidade da classifica√ß√£o multilabel.  

- **Dataset obtido em**: [CelebA no Kaggle](https://www.kaggle.com/datasets/jessicali9530/celeba-dataset)  
- **Mais informa√ß√µes em**: [MMLAB](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html)


## üß† 2. ResNet50: deep leaning network
---
A **ResNet50** (Residual Neural Network com 50 camadas) √© uma arquitetura de rede neural profunda introduzida em 2015 pela [Microsoft Research](https://en.innovatiana.com/post/discover-resnet-50). 

A ResNet50 foi treinada no dataset ImageNet, que cont√©m milh√µes de imagens distribu√≠das em 1.000 categorias. Nesse contexto, a ResNet50 alcan√ßou uma acur√°cia de top-5 de 92,1%, demonstrando sua efic√°cia em tarefas de classifica√ß√£o de imagens. Embora existam arquiteturas mais recentes que superam a ResNet50 em termos de acur√°cia, como a ResNet152V2 e as redes da fam√≠lia EfficientNet, a ResNet50 oferece um bom equil√≠brio entre desempenho e efici√™ncia computacional [Keras Applications](https://keras.io/api/applications/).  

A ResNet50 √© uma boa escolha em tarefas de reconhecimento facial devido √† sua capacidade de capturar caracter√≠sticas faciais complexas. Apesar de n√£o ser a arquitetura mais recente, sua efici√™ncia e robustez a tornam uma escolha confi√°vel para essa aplica√ß√£o.  

## üìä 3. Evaluation metrics
---
A m√©trica **AUC** (√Årea sob a Curva ROC) avalia a capacidade do modelo de distinguir entre classes positivas e negativas, medindo a √°rea sob a curva ROC (Receiver Operating Characteristic).  

A m√©trica AUC considera tanto a taxa de verdadeiros positivos quanto a de falsos positivos, equilibrando a avalia√ß√£o do modelo em cen√°rios onde h√° diferen√ßas significativas na distribui√ß√£o das classes.  
A m√©trica Recall e precision


## üöÄ 4. Entenda o processo de Transfer Learning
---
Transfer Learning √© uma t√©cnica de aprendizado onde um modelo treinado em uma base de dados √© adaptado para outra tarefa semelhante, evitando o treinamento do zero e otimizando tempo e recursos.  

**Por que √© √∫til?**  

- **Aproveitamento de conhecimento pr√©vio:** Permite alavancar conhecimento aprendido em bases grandes, como o ImageNet.  
- **Redu√ß√£o de overfitting:** Especialmente importante em bases menores, onde um modelo treinado do zero pode superajustar os dados de treinamento.  
- **Efici√™ncia computacional:** Economiza recursos ao reutilizar pesos previamente treinados.  

**Etapas de Transfer Learning neste projeto:**  

1. **Escolha do modelo base:** a rede ResNet50 pr√©-treinada no ImageNet foi a escolha para este projeto. 
2. **Congelamento de camadas:** As primeiras camadas da ResNet50 foram congeladas, preservando os pesos que capturam caracter√≠sticas gerais das imagens, como bordas e texturas. 
3. **Adapta√ß√£o do modelo:** a √∫ltima camada foi adaptada para classificar os 40 atributos do CelebA.  
4. **data selection and preparation**: 100 imagens de cada classe foram escolhidas aleatoriamente para o treinamento. Algumas imagens foram sorteadas para serem transformadas (rota√ß√£o, zoom, aumento ou diminui√ß√£o de contraste, brilho e satura√ß√£o).
4. **Treinamento personalizado:** as novas camadas adicionadas foram treinadas com o dataset permitindo que o modelo aprendesse caracter√≠sticas espec√≠ficas do CelebA.  

## 5. Conclus√£o

O projeto atingiu o objetivo geral, que foi a escolha de uma rede e dataset para aplica√ß√£o de transfer learning. Esta solu√ß√£o tamb√©m teve como adicional a explora√ß√£o dos desafios de uma classifica√ß√£o multilabel. 

Depois do modelo treinado, a etapa de testes produziu um dataframe com os valores de y e ≈∑. Esse dataframe ser√° carregado no Projeto 3 deste reposit√≥rio, onde ser√° explorado o c√°lculo de m√©tricas de avalia√ß√£o de modelos de classifica√ß√£o.

Por agora √© isso. Obrigada pela aten√ß√£o e at√© a pr√≥xima.

---

**Refer√™ncias:**  
- [Artigo Original ResNet](https://arxiv.org/abs/1512.03385)  
- [ImageNet Benchmark](https://paperswithcode.com/sota/image-classification-on-imagenet)  
- [AUC: Receiver Operating Characteristic](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc)  
- [Compara√ß√£o de M√©tricas: F1, AUC, Accuracy](https://neptune.ai/blog/f1-score-accuracy-roc-auc-pr-auc)  

