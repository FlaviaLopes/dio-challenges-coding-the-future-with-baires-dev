
# Treinamento de redes neurais com transfer learning

üìå Neste projeto uso a t√©cnica de Transfer Learning para classifica√ß√£o multilabel de atributos faciais com a rede ResNet50.

A solu√ß√£o est√° neste diret√≥rio, no notebook do Google Colab [`Treinamento_de_redes_neurais_com_transfer_learning.ipynb`](https://github.com/FlaviaLopes/dio-challenges-coding-the-future-with-baires-dev/blob/main/projeto_1/Treinamento_de_redes_neurais_com_transfer_learning.ipynb).

$Mas$ $antes$ $disso$... Entenda um pouco mais sobre o desafio.

> **Desafio:** 
"O projeto consiste em aplicar o m√©todo de Transfer Learning em uma rede de Deep Learning usando a linguagem Python e no ambiente COLAB. Neste projeto, voc√™ pode usar sua pr√≥pria base de dados (exemplo: fotos suas, dos seus pais, dos seus amigos, dos seus animais dom√©sticos, etc). O exemplo de gatos e cachorros pode ser substitu√≠do por duas outras classes do seu interesse. O Dataset criado em nosso projeto anterior pode ser utilizado agora."

üéØ **Etapas**
- Para atingir os objetivos propostos, as seguintes etapas foram realizadas:  
  1. **Escolha da base e prepara√ß√£o dos dados:** escolhi o dataset CelebA (ver se√ß√£o 1).  
  2. **Implementa√ß√£o de Transfer Learning com a rede ResNet50:** retreinei a rede com as imagens do dataset selecionado (ver se√ß√£o 2).  
  3. **Treinamento e valida√ß√£o do modelo com m√©tricas espec√≠ficas:** utilizei as m√©tricas AUC, recall e precision (ver se√ß√£o 3).

üìù **Contexto**: A se√ß√£o 1 d√° mais detalhes sobre a base utilizada, as se√ß√µes 2 a 4 trazem mais informa√ß√µes sobre a rede utilizada, m√©tricas de avalia√ß√£o e o processo de transfer learning.
__Obs.:__ o enunciado prop√µe o uso de duas classes, e o CelebA √© um dataset de faces multilabel com 40 atributos. Ou seja, uma imagem pode ter at√© 40 labels simultaneamente. Por prefer√™ncia pessoal resolvi explorar esse desafio, j√° que o objetivo desta atividade √© aplicar as t√©cnicas de transfer learning, n√£o necessariamente apresentar um modelo excelente. Obviamente, devido ao desbalanceamento desse dataset em torno de alguns labels, j√° era esperado que o modelo n√£o performasse bem para algumas classes (ver notebook `Feature Engineering Celeb A.ipynb`). Entretanto, com as m√©tricas de desempenho deste primeiro prot√≥tipo, eu pude explorar melhor o problema no projeto_3, e construir uma estrat√©gia para data augmentation de algumas classes, o que pode melhorar o desempenho do modelo em uma segunda itera√ß√£o de desenvolvimento.

---
üîç **Desempenho do modelo**
- Input data:
	- Foram selecionadas 3.800 imagens para o treinamento, e 38 classes das 40 dispon√≠veis (ver `Feature Engineering Celeb A.ipynb`). A imagem a seguir ilustra a distribui√ß√£o das classes do dataset, a terceira imagem √© a distribui√ß√£o da amostra utilizada para o treino.
![classes distribution](https://raw.githubusercontent.com/FlaviaLopes/dio-challenges-coding-the-future-with-baires-dev/refs/heads/main/projeto_1/output/images/dataset_classes_distribution.png)
- Training phase:
	- A cabe√ßa da rede ResNet50 foi treinada por 8 √©pocas (Early Stop foi ativado).
- Fine tunning phase:
	- As primeiras 10 camadas continuaram congeladas, e as demais foram descongeladas para que o treinamento continuasse, a uma taxa de aprendizado menor, por mais 20 √©pocas.
- A imagem a seguir resume a evolu√ß√£o do treinamento atrav√©s das m√©tricas: AUC, Precision, Recall e loss (binary cross entropy). O tra√ßo vertical indica o fim da fase de treinamento e in√≠cio do fine tunning, onde as m√©tricas de precis√£o e AUC caem, naturalmente, mas depois come√ßam a evoluir. As m√©tricas s√£o uma m√©dia do desempenho das classes, cerca de 3 classes desempenharam bem, mais outras 3 desempenharam razoavelmente. As m√©tricas deste modelo s√£o discutidas no projeto_3.

![Training metrics](https://raw.githubusercontent.com/FlaviaLopes/dio-challenges-coding-the-future-with-baires-dev/refs/heads/main/projeto_1/output/images/ResNet50_CelebA_training_finetune_history.png)

üîç **Como o modelo classificou...**

- A seguir, temos quatro fotos de pessoas preditas pelo modelo: duas celebridades brasileiras, Lena e eu.
- Blond_Hair parece ser um problema, todas as imagens foram rotuladas assim. Heavy_Makeup tamb√©m. Blond_Hair est√° fortemente correlacionada a Heavy_Makeup, Wavy_Hair, Oval_Face, Rosy_Cheeks e Point_Nose.
- Como discutido no notebook `Feature Engineering CelebA`, devido a alta correla√ß√£o entre Young e Gray_Hair, temos que o modelo tende a classificar mulheres como jovens, provavelmente porque h√° poucas mulheres grisalhas na base, independentemente da idade delas. 

![Image grid](https://raw.githubusercontent.com/FlaviaLopes/dio-challenges-coding-the-future-with-baires-dev/refs/heads/main/projeto_1/output/images/images_grid_with_predictions.png)

---

## üì∏ 1. CelebA dataset
---
O **CelebA** √© um dataset de imagens de rostos de celebridades, desenvolvido por pesquisadores da **The Chinese University of Hong Kong**. Cont√©m mais de 202 mil imagens rotuladas com 40 atributos faciais bin√°rios, como _smiling_, _young_, _black-hair_, _brown-hair_, _blond-hair_, _big-lips_, dentre outros. √â uma base bastante √∫til para treinamento de modelos de reconhecimento de atributos faciais.

- **Dataset obtido em**: [CelebA no Kaggle](https://www.kaggle.com/datasets/jessicali9530/celeba-dataset)  
- **Mais informa√ß√µes em**: [MMLAB](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html)


## üß† 2. ResNet50: deep leaning network
---
A **ResNet50** (Residual Neural Network com 50 camadas) √© uma arquitetura de rede neural profunda introduzida em 2015 pela [Microsoft Research](https://en.innovatiana.com/post/discover-resnet-50). 

A ResNet50 foi treinada no dataset ImageNet, que cont√©m milh√µes de imagens distribu√≠das em 1.000 categorias. Nesse contexto, a ResNet50 alcan√ßou uma acur√°cia de top-5 de 92,1%, demonstrando sua efic√°cia em tarefas de classifica√ß√£o de imagens. Embora existam arquiteturas mais recentes que superam a ResNet50 em termos de acur√°cia, como a ResNet152V2 e as redes da fam√≠lia EfficientNet, a ResNet50 oferece um bom equil√≠brio entre desempenho e efici√™ncia computacional [Keras Applications](https://keras.io/api/applications/).  

A ResNet50 √© uma boa escolha em tarefas de reconhecimento facial devido √† sua capacidade de capturar caracter√≠sticas faciais complexas.   

## üìä 3. Evaluation metrics
---
A m√©trica **AUC** (√Årea sob a Curva ROC) avalia a capacidade do modelo de distinguir entre classes positivas e negativas, medindo a √°rea sob a curva ROC (Receiver Operating Characteristic).  

A m√©trica AUC considera tanto a taxa de verdadeiros positivos quanto a de falsos positivos, equilibrando a avalia√ß√£o do modelo em cen√°rios onde h√° diferen√ßas significativas na distribui√ß√£o das classes.  

Neste modelo, a AUC multilabel foi utilizada para monitorar a evolu√ß√£o do treino. A fun√ß√£o de perda foi Bynary Cross Entropy.


## üöÄ 4. Entenda o processo de Transfer Learning
---
Transfer Learning √© uma t√©cnica de aprendizado onde um modelo treinado em uma base de dados √© adaptado para outra tarefa semelhante, evitando o treinamento do zero e otimizando tempo e recursos.  

**Por que √© √∫til?**  

- **Aproveitamento de conhecimento pr√©vio:** Permite alavancar conhecimento aprendido em bases grandes, como o ImageNet.  
- **Redu√ß√£o de overfitting:** Especialmente importante em bases menores, onde um modelo treinado do zero pode superajustar os dados de treinamento.  
- **Efici√™ncia computacional:** Economiza recursos ao reutilizar pesos previamente treinados.  

**Etapas de Transfer Learning neste projeto:**  

1. **Escolha do modelo base:** a rede ResNet50 pr√©-treinada no ImageNet foi a escolha para este projeto. 
2. **Congelamento de camadas:** As primeiras camadas da ResNet50 foram congeladas, preservando os pesos que capturam caracter√≠sticas gerais das imagens, como bordas e texturas. 
3. **Adapta√ß√£o do modelo:** a √∫ltima camada foi adaptada para classificar os 38 atributos do CelebA.  
4. **Sele√ß√£o e prepara√ß√£o dos dados**: 3..800 imagens foram escolhidas para o treinamento, de maneira que diminuisse o desbalanceamento entre as classes. O data augmentation foi feito de maneira geral nesta primeira itera√ß√£o.
4. **Treinamento personalizado:** as novas camadas adicionadas foram treinadas com o dataset permitindo que o modelo aprendesse caracter√≠sticas espec√≠ficas do CelebA por 8 √©pocas. Depois, durante o fine tunning a rede foi treinada por mais 20 √©pocas.

## 5. Conclus√£o

O projeto atingiu o objetivo geral, que foi a escolha de uma rede e dataset para aplica√ß√£o de transfer learning. Esta solu√ß√£o tamb√©m teve como adicional a explora√ß√£o dos desafios de uma classifica√ß√£o multilabel. 

Depois do modelo treinado, a etapa de testes produziu um dataframe com os valores de y e ≈∑. Esse dataframe ser√° carregado no Projeto 3 deste reposit√≥rio, onde ser√° explorado o c√°lculo de m√©tricas de avalia√ß√£o de modelos de classifica√ß√£o.

Por agora √© isso. Obrigada pela aten√ß√£o e at√© a pr√≥xima.

---

**Refer√™ncias:**  
- [Artigo Original ResNet](https://arxiv.org/abs/1512.03385)  
- [ImageNet Benchmark](https://paperswithcode.com/sota/image-classification-on-imagenet)  
- [AUC: Receiver Operating Characteristic](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc)  
- [Compara√ß√£o de M√©tricas: F1, AUC, Accuracy](https://neptune.ai/blog/f1-score-accuracy-roc-auc-pr-auc)  

